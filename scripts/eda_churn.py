# -*- coding: utf-8 -*-
"""EDA_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ljlorv3FT6FgcSFHtf4sVTSJq77KbBg6

# Dataset - Telco Customer Churn

O dataset Telco Customer Churn, disponibilizado pela IBM, cont√©m informa√ß√µes sobre clientes de uma empresa de telecomunica√ß√µes e √© utilizado para a an√°lise e previs√£o do fen√¥meno de churn, ou seja, o cancelamento de servi√ßos pelos clientes. Composto por 7.043 inst√¢ncias e 20 atributos, este conjunto de dados inclui tanto vari√°veis categ√≥ricas quanto num√©ricas, englobando aspectos como dados demogr√°ficos, informa√ß√µes contratuais, uso de servi√ßos e valores monet√°rios. A vari√°vel-alvo, Churn, classifica os clientes como aqueles que cancelaram ou n√£o os servi√ßos da empresa.

Entre as vari√°veis presentes no dataset, destacam-se informa√ß√µes como gender, SeniorCitizen, tenure, Contract, PaymentMethod, MonthlyCharges, e TotalCharges, que fornecem uma vis√£o detalhada dos clientes e do relacionamento contratual com a empresa. No entanto, algumas colunas, como a TotalCharges, exigem pr√©-processamento adicional devido a inconsist√™ncias no tipo de dado.

Este dataset √© amplamente utilizado para a constru√ß√£o de modelos preditivos de classifica√ß√£o bin√°ria, permitindo a an√°lise de fatores que influenciam o churn dos clientes e contribuindo para a otimiza√ß√£o de estrat√©gias empresariais no setor de telecomunica√ß√µes.

Features

1. gender
‚Üí G√™nero do cliente (masculino ou feminino).

2. SeniorCitizen
‚Üí Se o cliente √© idoso (1 = Sim, 0 = N√£o).

3. Partner
‚Üí Se o cliente tem parceiro/parceira (Sim ou N√£o).

4. Dependents
‚Üí Se o cliente tem dependentes (filhos, outros familiares).

5. tenure
‚Üí Tempo de perman√™ncia na empresa (em meses).

6. PhoneService
‚Üí Se o cliente possui servi√ßo de telefone (Sim ou N√£o).

7. MultipleLines
‚Üí Se o cliente possui m√∫ltiplas linhas telef√¥nicas (Sim, N√£o ou N√£o possui servi√ßo telef√¥nico).

8. InternetService
‚Üí Tipo de servi√ßo de internet (DSL, fibra √≥tica ou nenhum).

9. OnlineSecurity
‚Üí Se o cliente possui seguran√ßa online (prote√ß√£o contra v√≠rus).

10. OnlineBackup
‚Üí Se o cliente possui servi√ßo de backup online.

11. DeviceProtection
‚Üí Se o cliente possui prote√ß√£o para seus dispositivos (manuten√ß√£o, suporte).

12. TechSupport
‚Üí Se o cliente possui suporte t√©cnico.

13. StreamingTV
‚Üí Se o cliente possui servi√ßo de streaming de TV.

14. StreamingMovies
‚Üí Se o cliente possui servi√ßo de streaming de filmes.

15. Contract
‚Üí Tipo de contrato do cliente (mensal, anual, bianual).

16. PaperlessBilling
‚Üí Se o cliente recebe a fatura apenas online (sem papel).

17. PaymentMethod
‚Üí M√©todo de pagamento (boleto eletr√¥nico, cheque enviado, d√©bito autom√°tico, cart√£o de cr√©dito autom√°tico).

18. MonthlyCharges
‚Üí Valor da fatura mensal do cliente (em d√≥lares).

19. TotalCharges
‚Üí Valor total pago pelo cliente at√© o momento (em d√≥lares).

20. Churn
‚Üí Se o cliente cancelou o servi√ßo (Sim = cancelou, N√£o = ainda est√° ativo).

A an√°lise explorat√≥ria de dados foi conduzida de acordo com a natureza e a estrutura dos dados apresentados. Cada tipo de dataframe, necessita de uma abordagem espec√≠fica, considerando suas caracter√≠sticas.

# 1. Importa√ß√£o dos dados

## 1.1. Importa√ß√£o
"""

from google.colab import files

# Abre a janela para selecionar o arquivo
uploaded = files.upload()

# Depois, para ler o arquivo
import pandas as pd

matriz = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')

"""## 1.2. Caracter√≠sticas do dataset bruto"""

# Informa√ß√µes b√°sicas
print(f"N√∫mero de inst√¢ncias: {matriz.shape[0]}")
print(f"N√∫mero de colunas: {matriz.shape[1]}\n")

print("Colunas e tipos de vari√°veis:")
print("-" * 50)

# Percentual para definir "poucas categorias"
limite_categoria = 0.10 * matriz.shape[0]  # 10% do n√∫mero de inst√¢ncias

# Para cada coluna
for coluna in matriz.columns:
    tipo = matriz[coluna].dtype

    if pd.api.types.is_numeric_dtype(matriz[coluna]):
        print(f"üîπ {coluna}: Num√©rica")

    elif pd.api.types.is_object_dtype(matriz[coluna]) or pd.api.types.is_categorical_dtype(matriz[coluna]):
        n_categorias = matriz[coluna].nunique()
        print(f"üî∏ {coluna}: Categ√≥rica ({n_categorias} categorias)")

        # Se o n√∫mero de categorias for pequeno (menos de 10% do total de inst√¢ncias)
        if n_categorias <= limite_categoria:
            categorias = matriz[coluna].unique()
            print(f"    Categorias: {categorias}")

    else:
        print(f"üîπ {coluna}: Tipo especial ({tipo})")

print("-" * 50)

"""## 1.3. Visualiza√ß√£o da matriz"""

# Visualiza√ß√£o da matriz
matriz.head()

"""# 2. Entendimento inicial do dataset

## 2.1. Removendo coluna de customerID

A coluna 'customerID' deve ser removida da an√°lise porque ela funciona apenas como um identificador √∫nico para cada cliente e n√£o carrega nenhuma informa√ß√£o √∫til para os modelos de machine learning. Como possui 7043 categorias distintas (uma para cada inst√¢ncia), ela n√£o contribui para padr√µes ou rela√ß√µes entre as vari√°veis e pode at√© prejudicar o desempenho do modelo ao introduzir ru√≠do ou complexidade desnecess√°ria. Mant√™-la pode levar o modelo a aprender associa√ß√µes esp√∫rias que n√£o se repetem em novos dados.
"""

#Remover primeira coluna
matriz = matriz.drop(columns=['customerID'])

"""## 2.2. Atualiza√ß√£o dos nomes das colunas

Visualiza√ß√£o dos nomes da colunas atuais
"""

# Nome das colunas
matriz.columns

"""## 2.3. Informa√ß√µes num√©ricas sobre a matriz

Informa√ß√µes:
* N√∫mero total de entradas (linhas)
* N√∫mero de colunas
* Nome de cada coluna
* Quantidade de valores n√£o nulos em cada coluna
* Tipo de dado de cada coluna (int64, float64, object, etc.)
* Uso de mem√≥ria aproximado
"""

matriz.info()

"""## 2.4. Quantidade de valores nulos

Exibir a quantidade de valores nulos por cada coluna da matriz
"""

# Quantidade de valores nulos.
matriz.isnull().sum()

"""## 2.5. Presen√ßa de valores inv√°lidos

Nesta subse√ß√£o s√£o feitas as seguintes tarefas:
* A presen√ßa de "NaN" e "?" por coluna
* Identifica√ß√£o de valores suspeitos (espa√ßos em branco)
* Remo√ß√£o das linhas com valores ausentes
* Identifica√ß√£o das colunas que parecem ser num√©ricas, mas est√£o como objeto (texto)
* Convers√£o das colunas "object" para "float"

### 2.5.1 Presen√ßa de "NaN" e "?"
"""

# Para cada coluna
  # Coluna: nome
  # Tipo: categ√≥rica, bin√°ria, num√©rica inteira, etc.
  # Se possui valores NaN
  # Se possui o caractere "?" (muito usado como marcador de valor ausente)

# Fun√ß√£o para analisar coluna
def analisar_coluna(col):
    serie = matriz[col]
    tipo_dado = serie.dtype
    valores_unicos = serie.dropna().unique()
    num_unicos = len(valores_unicos)

    # Detecta se h√° '?'
    possui_interrogacao = serie.astype(str).str.contains(r'^\?$').any()

    # Define tipo da vari√°vel
    if tipo_dado == 'object':
        if num_unicos == 2:
            tipo_variavel = 'Bin√°ria (categ√≥rica)'
        else:
            tipo_variavel = 'Categ√≥rica'
        escala = f"Categorias: {list(valores_unicos)}"
    elif pd.api.types.is_numeric_dtype(serie):
        if num_unicos == 2:
            tipo_variavel = 'Bin√°ria (num√©rica)'
        elif pd.api.types.is_integer_dtype(serie):
            tipo_variavel = 'Num√©rica inteira'
        else:
            tipo_variavel = 'Num√©rica cont√≠nua'
        escala = f"Valores entre {serie.min()} e {serie.max()}"
    else:
        tipo_variavel = 'Outro'
        escala = 'N√£o identificado'

    possui_nan = serie.isna().any()

    return {
        'Tipo': tipo_variavel,
        'Escala': escala,
        'Possui NaN': possui_nan,
        'Possui "?"': possui_interrogacao
    }

# Analisa todas as colunas
analise_completa = {col: analisar_coluna(col) for col in matriz.columns}

# Exibe o resultado de forma organizada
for col, info in analise_completa.items():
    print(f"\nColuna: {col}")
    for chave, valor in info.items():
        print(f"  {chave}: {valor}")

"""### 2.5.2. Identificar valores suspeitos: espa√ßos em branco"""

# Identificar valores suspeitos: espa√ßos em branco
print("\nAnalisando valores suspeitos (espa√ßos em branco ou strings vazias):")
for coluna in matriz.columns:
    if matriz[coluna].dtype == 'object':
        qtde_brancos = (matriz[coluna].str.strip() == '').sum()
        if qtde_brancos > 0:
            print(f"- {coluna}: {qtde_brancos} valores em branco")

"""### 2.5.3. Remo√ß√£o dos espa√ßos vazios"""

# Remover linhas com valores ausentes (NaN) - string
matriz = matriz[matriz['TotalCharges'] != '']

# Remover linhas com valores ausentes (NaN) na coluna 'TotalCharges'
matriz = matriz.dropna(subset=['TotalCharges'])

# Verificar se as linhas com NaN foram removidas
print("\nLinhas com valores ausentes em 'TotalCharges' foram removidas:")
print(matriz.isnull().sum())

"""### 2.5.4. Colunas que parecem ser num√©ricas"""

import pandas as pd

# Verificar colunas que est√£o como texto, mas deveriam ser num√©ricas
possiveis_numericas = []

for coluna in matriz.columns:
    if matriz[coluna].dtype == 'object':
        # Limpa espa√ßos e remove strings vazias
        serie_limpa = matriz[coluna].dropna().astype(str).str.strip()
        serie_filtrada = serie_limpa[serie_limpa != '']
        try:
            pd.to_numeric(serie_filtrada, errors='raise')
            possiveis_numericas.append(coluna)
        except Exception as e:
            print(f"Falha ao converter '{coluna}': {e}")

if possiveis_numericas:
    print("\nAs seguintes colunas est√£o como 'object', mas parecem ser num√©ricas:")
    for col in possiveis_numericas:
        print(f"- {col}")
else:
    print("\nN√£o foram encontradas colunas com suspeita de tipo errado.")

"""### 2.5.5. Convers√£o da coluna "object" para "float"

A vari√°vel 'TotalCharges' deveria ser num√©rica, mas parece estar lida como texto/categ√≥rica.
Aqui, √© feita a convers√£o da coluna para float.
"""

# Corrigir a vari√°vel TotalCharges
import pandas as pd
matriz['TotalCharges'] = pd.to_numeric(matriz['TotalCharges'], errors='coerce')

# Verifica o tipo de dados da coluna
print(matriz['TotalCharges'].dtype)

"""## 2.6. Verifica√ß√£o de colunas duplicadas

Esse c√≥digo verifica se existem colunas duplicadas em um DataFrame ‚Äî ou seja, colunas diferentes que t√™m exatamente os mesmos valores linha por linha. Ele faz isso comparando cada par de colunas entre si.
"""

# Verificar colunas duplicadas
duplicadas = []
colunas = matriz.columns

for i in range(len(colunas)):
    for j in range(i + 1, len(colunas)):
        if matriz[colunas[i]].equals(matriz[colunas[j]]):
            duplicadas.append((colunas[i], colunas[j]))

# Exibe os pares de colunas duplicadas
for c1, c2 in duplicadas:
    print(f"Colunas '{c1}' e '{c2}' s√£o duplicadas.")

"""## 2.7. Verifica√ß√£o de valores √∫nicos

Esse c√≥digo verifica quantos valores √∫nicos existem em cada coluna do DataFrame matriz. Serve para:
* Identificar colunas constantes (com apenas 1 valor).
* Detectar colunas com alta cardinalidade (ex: IDs, nomes √∫nicos).
* Avaliar colunas que podem precisar de tratamento especial (como transforma√ß√£o categ√≥rica, remo√ß√£o ou codifica√ß√£o).
"""

# Verificar valores √∫nicos
valores_unicos = matriz.nunique()
print(valores_unicos)

"""## 2.8. Verificar linhas duplicadas

Identificar linhas que est√£o duplicadas e remove-as mantendo a primeira.
"""

#Detectar duplicatas - linhas
#Verifica se existem linhas repetidas no DataFrame:
duplicatas = matriz.duplicated()
print(matriz[duplicatas])

# Contar duplicatas - linhas
print(f"\nTotal de linhas duplicadas: {matriz.duplicated().sum()}")

# Remover duplicatas
# Remove as duplicatas mantendo a primeira ocorr√™ncia
matriz = matriz.drop_duplicates()

"""## 2.9. Verificar cardinalidade

A cardinalidade ajudar a identificar colunas que:
* S√£o f√°ceis de codificar (baixa cardinalidade ‚Äî poucos valores √∫nicos, como "Sim"/"N√£o").
* Podem causar problemas (alta cardinalidade ‚Äî muitos valores √∫nicos, como "customerID", nomes ou c√≥digos).
* Alta cardinalidade pode prejudicar modelos de machine learning, especialmente com codifica√ß√µes como one-hot (gera muitas colunas e risco de overfitting).
* Pode indicar colunas que devem ser removidas (como IDs).
* Ajuda na escolha da estrat√©gia de pr√©-processamento (label encoding, hashing, etc.).
"""

# Verificar cardinalidade
# Seleciona apenas colunas categ√≥ricas (strings/objetos)
colunas_categoricas = matriz.select_dtypes(include='object')

# Total de linhas no DataFrame
total_linhas = len(matriz)

print("Cardinalidade das vari√°veis categ√≥ricas:")
print()

# Para cada coluna categ√≥rica, calcula e avalia a cardinalidade
# Mais de 10% das linhas t√™m categorias diferentes √© considerada alta cardinalidade
for coluna in colunas_categoricas.columns:
    unicos = matriz[coluna].nunique()
    proporcao = unicos / total_linhas
    status = "ALTA" if proporcao > 0.1 else "BAIXA"

    print(f"Coluna: {coluna}")
    print(f"  ‚Üí Valores √∫nicos: {unicos}")
    print(f"  ‚Üí Propor√ß√£o: {proporcao:.2%}")
    print(f"  ‚Üí Cardinalidade: {status}")
    print()

"""# 3. Estat√≠sticas descritivas

## 3.1. Vari√°veis num√©ricas - descri√ß√£o

Nesta subse√ß√£o s√£o analisadas as vari√°veis num√©ricas quanto a:
* Quantidade de valores n√£o nulos
* M√©dia
* Desvio padr√£o
* Quartos e valores extremos
"""

matriz.describe()

"""## 3.2. Vari√°veis categ√≥ricas - descri√ß√£o e convers√£o

Nesta subse√ß√£o s√£o analisadas as vari√°veis categ√≥ricas quanto a:
* Descri√ß√£o: frequ√™ncia da quantidade de valores em cada coluna.
* Label Encoding: convers√£o e mapeamento das vari√°veis bin√°rias para valores num√©ricos
* Verifica√ß√£o se existem valores inesperados ap√≥s a convers√£o Label Encoding.
* One-Hot Encoding: convers√£o e mapeamento das vari√°veis com mais de 2 categoria. Bem como, cria√ß√£o de novas colunas, remo√ß√£o de colunas redundantes E descri√ß√£o das colunas finais.
* Verifica√ß√£o se existem valores inesperados ap√≥s a convers√£o One-Hot Encoding.
* Verifica a presen√ßa de valores "NaN" e "?" ap√≥s a codifica√ß√£o One-Hot Endoding
* Remove linhas com valores "NaN"
* Visualiza a matriz ap√≥s transforma√ß√µes

### 2.2.1. Descri√ß√£o
"""

# DESCRI√á√ÉO - VARI√ÅVEIS CATEG√ìRICAS
  # Os valores √∫nicos em cada coluna categ√≥rica
  # Quantas vezes cada um aparece (frequ√™ncia absoluta)

# Seleciona colunas categ√≥ricas
colunas_cat = matriz.select_dtypes(include='object')

# Frequ√™ncia de valores em cada coluna categ√≥rica
print("\nFrequ√™ncia dos valores nas vari√°veis categ√≥ricas:")
for col in colunas_cat.columns:
    print(f"\nColuna: {col}")
    print(matriz[col].value_counts())

"""### 2.2.2. Vari√°veis bin√°rias - Label Encoding"""

import pandas as pd

# Colunas bin√°rias
colunas_binarias = [
    'gender', 'Partner', 'Dependents', 'PhoneService',
    'PaperlessBilling', 'Churn'
]

# Diagn√≥stico: valores √∫nicos antes do mapeamento
print("Valores √∫nicos antes do mapeamento:")
print("--------------------------------------")
for coluna in colunas_binarias:
    print(f"- {coluna}: {matriz[coluna].unique()}")


# Mapeamento bin√°rio
for coluna in colunas_binarias:
    if coluna == 'gender':
        matriz[coluna] = matriz[coluna].map({'Female': 0, 'Male': 1})
    else:
        matriz[coluna] = matriz[coluna].map({'No': 0, 'Yes': 1})

# Verifica√ß√£o final: valores √∫nicos e poss√≠veis NaNs
print("\nMapeamento realizado nas vari√°veis bin√°rias:")
print("--------------------------------------")
print("- gender: Female = 0, Male = 1")
print("- Partner: No = 0, Yes = 1")
print("- Dependents: No = 0, Yes = 1")
print("- PhoneService: No = 0, Yes = 1")
print("- PaperlessBilling: No = 0, Yes = 1")
print("- Churn: No = 0, Yes = 1")

print("\nValores √∫nicos ap√≥s o mapeamento:")
print("--------------------------------------")
for coluna in colunas_binarias:
    print(f"- {coluna}: {matriz[coluna].unique()}")

# Checar se h√° NaN
print("\nVerificando se h√° valores NaN ap√≥s o mapeamento:")
print(matriz[colunas_binarias].isnull().sum())

"""### 2.2.3. Verificar a presen√ßa de valores inesperados ap√≥s a convers√£o - Label Encoding"""

#Verificar se existem valores inesperados:
for coluna in colunas_binarias:
    print(f"{coluna}: {matriz[coluna].unique()}")

"""### 2.2.4. Vari√°veis com mais de 2 categorias - One-Hot Encoding"""

# Colunas com 3 ou mais categorias (One-Hot Encoding)
colunas_multicategoricas = [
    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',
    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',
    'Contract', 'PaymentMethod'
]

# Diagn√≥stico: categorias √∫nicas antes do One-Hot Encoding
print("Categorias √∫nicas antes do One-Hot Encoding:")
print("-------------------------------------------------")
categorias_removidas = []

for coluna in colunas_multicategoricas:
    categorias = matriz[coluna].dropna().unique().tolist()
    print(f"- {coluna}: {categorias}")
    if len(categorias) > 1:
        categorias_removidas.append(f"{coluna}_{categorias[0]}")  # Primeira ser√° descartada com drop_first

# Aplicar One-Hot Encoding com drop_first=True
matriz = pd.get_dummies(matriz, columns=colunas_multicategoricas, drop_first=True)

# Identificar novas colunas criadas
novas_colunas = [col for col in matriz.columns if any(col.startswith(prefix + "_") for prefix in colunas_multicategoricas)]

# Converter booleanos para inteiros (0 e 1)
matriz[novas_colunas] = matriz[novas_colunas].astype(int)

# Detectar e remover colunas redundantes (ex: "No internet service", "No phone service")
redundantes = [col for col in novas_colunas if any(txt in col.lower() for txt in ['no internet service', 'no phone service'])]

matriz.drop(columns=redundantes, inplace=True)

# Exibir resumo das vari√°veis descartadas
print("\nVari√°veis removidas com drop_first (1¬™ categoria de cada vari√°vel):")
print("----------------------------------------------------------------------")
print(f"Total removidas (drop_first): {len(categorias_removidas)}")
for cat in categorias_removidas:
    print(f"- {cat}")

print("\nVari√°veis removidas por redund√¢ncia l√≥gica (ex: 'No internet service'):")
print("------------------------------------------------------------------------")
print(f"Total removidas (redundantes): {len(redundantes)}")
for col in redundantes:
    print(f"- {col}")

# Exibir as novas colunas finais ap√≥s limpeza
print("\nColunas finais ap√≥s One-Hot Encoding e limpeza:")
print("------------------------------------------------")
for coluna in colunas_multicategoricas:
    relacionadas = [c for c in matriz.columns if c.startswith(coluna + "_")]
    print(f"- {coluna}: {relacionadas}")

"""### 2.2.5.  Verificar a presen√ßa de valores inesperados ap√≥s a convers√£o - One-Hot Encoding"""

# Verificar se existem valores inesperados nas colunas
print("\nVerificando valores √∫nicos nas colunas criadas pelo One-Hot Encoding:")
print("-------------------------------------------------------------------------")
for coluna in colunas_multicategoricas:
    colunas_oh = [c for c in matriz.columns if c.startswith(coluna + "_")]
    for c in colunas_oh:
        valores_unicos = matriz[c].unique()
        print(f"{c}: {valores_unicos}")

"""MultipleLines_No: Se o valor √© True, significa que o cliente n√£o tem m√∫ltiplas linhas, e o valor 1 ser√° atribu√≠do. Se o valor for False, o cliente tem m√∫ltiplas linhas, e o valor ser√° 0.

### 2.2.6. Verifica a presen√ßa de valores "NaN" e "?" ap√≥s a codifica√ß√£o One-Hot Encoding
"""

# Para cada coluna
  # Coluna: nome
  # Tipo: categ√≥rica, bin√°ria, num√©rica inteira, etc.
  # Se possui valores NaN
  # Se possui o caractere "?" (muito usado como marcador de valor ausente)

# Fun√ß√£o para analisar colunas com NaN ou '?'
def colunas_com_nan_ou_interrogacao(df):
    colunas_problema = []

    for col in df.columns:
        serie = df[col]
        tem_nan = serie.isna().sum()
        tem_interrogacao = (serie.astype(str) == '?').sum()

        if tem_nan > 0 or tem_interrogacao > 0:
            colunas_problema.append({
                'Coluna': col,
                'Qtd_NaN': tem_nan,
                'Qtd_Interrogacao': tem_interrogacao
            })

    return colunas_problema

# Aplicar fun√ß√£o e exibir resultados
problemas = colunas_com_nan_ou_interrogacao(matriz)

print("\nColunas com valores ausentes (NaN) ou '?' detectadas:")
print("--------------------------------------------------------")
for item in problemas:
    print(f"- {item['Coluna']}: {item['Qtd_NaN']} NaN, {item['Qtd_Interrogacao']} '?'")

"""### 2.2.7. Remove linhas com valores "NaN"
"""

# Verificar quantidade total de NaNs antes
qtd_nan_antes = matriz.isna().sum().sum()
linhas_antes = matriz.shape[0]

print(f"Total de valores NaN antes da remo√ß√£o: {qtd_nan_antes}")
print(f"N√∫mero de linhas antes da remo√ß√£o: {linhas_antes}")

# Remover todas as linhas com qualquer NaN
matriz = matriz.dropna()

# Verificar quantidade total de NaNs depois
qtd_nan_depois = matriz.isna().sum().sum()
linhas_depois = matriz.shape[0]

print("\nRemo√ß√£o de linhas com valores NaN conclu√≠da.")
print(f"N√∫mero de linhas ap√≥s a remo√ß√£o: {linhas_depois}")
print(f"Total de valores NaN ap√≥s a remo√ß√£o: {qtd_nan_depois}")
print(f"Total de linhas removidas: {linhas_antes - linhas_depois}")

"""### 2.2.7. Visualiza a matriz ap√≥s transforma√ß√µes"""

matriz.head()

"""## 3.3. Medidas da estat√≠stica descritiva - ap√≥s codifica√ß√£o das colunas

Aqui, √© feita uma an√°lise da estat√≠stica descritiva das vari√°veis num√©ricas:
* M√©dia, Mediana, Moda, Desvio Padr√£o, Vari√¢ncia, IQR, Assimetria, Curtose.

An√°lise feita ap√≥s a codifica√ß√£o das colunas antes categ√≥ricas e agora num√©ricas.
"""

# Para vari√°veis num√©ricas
# Separa num√©ricas e categ√≥ricas
num_df = matriz.select_dtypes(include='number')
cat_df = matriz.select_dtypes(include='object')

# Estat√≠sticas para vari√°veis num√©ricas
media = num_df.mean()
mediana = num_df.median()
moda_num = num_df.mode().iloc[0]
desvio = num_df.std()
variancia = num_df.var()
q1 = num_df.quantile(0.25)
q3 = num_df.quantile(0.75)
iqr = q3 - q1
skew = num_df.skew()
kurt = num_df.kurt()

# Monta DataFrame com num√©ricas
estatisticas_numericas = pd.DataFrame({
    'M√©dia': media,
    'Mediana': mediana,
    'Moda': moda_num,
    'Desvio Padr√£o': desvio,
    'Vari√¢ncia': variancia,
    'IQR (Q3 - Q1)': iqr,
    'Assimetria (Skewness)': skew,
    'Curtose': kurt
})

# Exibe com 3 casas decimais nas num√©ricas
pd.options.display.float_format = '{:.3f}'.format
print(estatisticas_numericas)

"""# 4. Visualiza√ß√µes Univariadas

3 tipos de visualiza√ß√µes univariadas s√£o adequadas para esse contexto:
* Histograma: permite visualizar a distribui√ß√£o de frequ√™ncias de uma vari√°vel num√©rica cont√≠nua, como o tempo de perman√™ncia (tenure) ou o valor cobrado mensalmente (MonthlyCharges), facilitando a identifica√ß√£o de padr√µes, concentra√ß√µes e assimetrias nos dados.
* Boxplot: apresenta a mediana, os quartis e os outliers de uma vari√°vel, sendo √∫til para entender a dispers√£o e poss√≠veis valores extremos, como em TotalCharges, al√©m de permitir compara√ß√µes entre grupos, como clientes que cancelaram ou n√£o (Churn).
* Densidade/KDE: fornece uma estimativa suave da distribui√ß√£o de uma vari√°vel cont√≠nua, servindo como alternativa ao histograma, e √© especialmente √∫til para comparar visualmente diferentes subgrupos dentro de uma mesma vari√°vel.

## 4.1. Histograma - vari√°veis num√©ricas
"""

# HISTOGRAMA - vari√°veis num√©ricas
import matplotlib.pyplot as plt

for col in matriz.select_dtypes(include='number').columns:
    plt.figure(figsize=(6,4))
    matriz[col].hist(bins=30)
    plt.title(f'Histograma - {col}')
    plt.xlabel(col)
    plt.ylabel('Frequ√™ncia')
    plt.grid(True)
    plt.show()

"""## 4.2. Boxplots - vari√°veis num√©ricas"""

# BOXPLOTS - vari√°veis num√©ricas
import seaborn as sns
import matplotlib.pyplot as plt

# Filtrar apenas vari√°veis num√©ricas com mais de 2 valores distintos
colunas_multivalor = [
    col for col in matriz.select_dtypes(include='number').columns
    if matriz[col].nunique() > 2
]

# Gerar boxplots
for col in colunas_multivalor:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=matriz[col])
    plt.title(f'Boxplot - {col}')
    plt.xlabel(col)
    plt.show()

"""## 4.3. Densidade/KDE (Kernel Density Estimation)"""

# Densidade / KDE (Kernel Density Estimation)
import seaborn as sns
import matplotlib.pyplot as plt

# Loop apenas nas vari√°veis num√©ricas com mais de 2 valores √∫nicos
for col in matriz.select_dtypes(include='number').columns:
    if matriz[col].nunique() > 2:
        plt.figure(figsize=(6, 4))
        sns.kdeplot(data=matriz, x=col, fill=True)
        plt.title(f'Densidade (KDE) - {col}')
        plt.xlabel(col)
        plt.ylabel('Densidade')
        plt.grid(True)
        plt.show()

"""# 5. Visualiza√ß√µes Bivariadas

2 tipos de visualiza√ß√µes bivariadas s√£o adequadas para esse contexto:

* Gr√°fico de dispers√£o (scatterplot): permite visualizar a rela√ß√£o entre duas vari√°veis num√©ricas, como a correla√ß√£o entre MonthlyCharges e TotalCharges. Ele ajuda a identificar padr√µes, tend√™ncias lineares ou n√£o lineares e a presen√ßa de outliers entre as vari√°veis.
* Mapas de calor de correla√ß√£o (heatmap): mostra a intensidade da correla√ß√£o entre v√°rias vari√°veis, geralmente com uma matriz de correla√ß√£o. Esse tipo de visualiza√ß√£o √© √∫til para entender rapidamente quais vari√°veis possuem uma rela√ß√£o forte ou fraca entre si, como por exemplo, a correla√ß√£o entre tenure, MonthlyCharges e TotalCharges.

## 5.1. Gr√°fico de dispers√£o (scatterplot)
"""

# Gr√°fico de Dispers√£o (Scatterplot) - Rela√ß√£o entre duas vari√°veis num√©ricas
import seaborn as sns
import matplotlib.pyplot as plt

# Selecionar vari√°veis num√©ricas com mais de 2 valores √∫nicos
variaveis_validas = [
    col for col in matriz.select_dtypes(include='number').columns
    if matriz[col].nunique() > 2
]

# Gerar scatterplots entre combina√ß√µes dessas vari√°veis
for i in range(len(variaveis_validas)):
    for j in range(i + 1, len(variaveis_validas)):
        plt.figure(figsize=(6,4))
        sns.scatterplot(data=matriz, x=variaveis_validas[i], y=variaveis_validas[j])
        plt.title(f'Scatterplot: {variaveis_validas[i]} vs {variaveis_validas[j]}')
        plt.tight_layout()
        plt.show()

"""## 5.2. Mapas de calor de correla√ß√£o (heatmap)"""

#Mapa de Calor de Correla√ß√£o (Heatmap): correla√ß√µes entre vari√°veis num√©ricas.
correlacao = matriz.corr()

plt.figure(figsize=(20, 14))
sns.heatmap(correlacao, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title('Mapa de Correla√ß√£o')
plt.show()

"""# 6. Detec√ß√£o e remo√ß√£o de Outliers

## 6.1. Avaliando a distribui√ß√£o de cada vari√°vel

O c√≥digo tem como objetivo avaliar a distribui√ß√£o de cada vari√°vel num√©rica no DataFrame, para determinar se elas seguem uma distribui√ß√£o normal ou se apresentam assimetrias.
"""

# Avaliando a distribui√ß√£o de cada vari√°vel
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import shapiro
import pandas as pd

# Selecionar vari√°veis num√©ricas
variaveis_numericas = matriz.select_dtypes(include='number')

# DataFrame para armazenar os resultados
resultado_distribuicao = pd.DataFrame(columns=['Vari√°vel', 'Skewness', 'p-valor', 'Tipo de Distribui√ß√£o'])

# Loop pelas vari√°veis
for col in variaveis_numericas.columns:
    # Plot
    sns.displot(matriz[col], kde=True)
    plt.title(f'Distribui√ß√£o de {col}')
    plt.xlabel(col)
    plt.ylabel('Frequ√™ncia')
    plt.show()

    # C√°lculo de skewness
    skew = matriz[col].skew()

    # Teste de normalidade (Shapiro-Wilk, adequado para at√© 5000 amostras)
    # Reduz o tamanho se houver muitos dados
    amostra = matriz[col].dropna()
    if len(amostra) > 5000:
        amostra = amostra.sample(5000, random_state=42)
    stat, p = shapiro(amostra)

    # Classifica√ß√£o da distribui√ß√£o
    if p > 0.05 and abs(skew) < 0.5:
        tipo = 'Aproximadamente normal'
    elif skew > 0.5:
        tipo = 'Assim√©trica √† direita'
    elif skew < -0.5:
        tipo = 'Assim√©trica √† esquerda'
    else:
        tipo = 'Levemente assim√©trica'

    # Adiciona ao DataFrame de resultados
    resultado_distribuicao.loc[len(resultado_distribuicao)] = [col, round(skew, 2), round(p, 4), tipo]

# Exibe a tabela final
print("\nResumo das distribui√ß√µes:")
print(resultado_distribuicao)

"""## 6.2. IQR

IQR (Intervalo Interquartil): Mede a dispers√£o entre o 25¬∫ e o 75¬∫ percentil.

* Detec√ß√£o de outliers: Outliers podem distorcer an√°lises estat√≠sticas e a performance de modelos de aprendizado de m√°quina. Identificar e tratar esses valores √© importante, especialmente em modelos que s√£o sens√≠veis a dados extremos.

* Defini√ß√£o do multiplicador: O multiplicador (3, neste caso) √© um fator que determina a quantidade de "for√ßa" que voc√™ permite para um valor se desviar da m√©dia. Quando o multiplicador √© maior (por exemplo, 3), voc√™ √© mais rigoroso ao identificar outliers.

* Tratamento de outliers: Ap√≥s identificar os outliers, voc√™ pode decidir se deseja remov√™-los, transform√°-los ou trat√°-los de outra forma, dependendo da natureza dos dados e da an√°lise.
"""

#IQR (Intervalo Interquartil): Mede a dispers√£o entre o 25¬∫ e o 75¬∫ percentil. Valores fora de 3 vezes o IQR s√£o considerados outliers.
# Calcular IQR
# IQR (Intervalo Interquartil): Detecta outliers para qualquer vari√°vel num√©rica
import pandas as pd

# Seleciona apenas colunas num√©ricas
variaveis_numericas = matriz.select_dtypes(include='number')

# Lista para armazenar √≠ndices de outliers e contagem por coluna
outlier_indices = set()
contagem_por_coluna = {}
multiplicador = 3
# Loop para cada vari√°vel num√©rica
for coluna in variaveis_numericas.columns:
    Q1 = matriz[coluna].quantile(0.25)
    Q3 = matriz[coluna].quantile(0.75)
    IQR = Q3 - Q1
    limite_inferior = Q1 - multiplicador * IQR
    limite_superior = Q3 + multiplicador * IQR

    # Encontra √≠ndices dos outliers na coluna
    indices = matriz[(matriz[coluna] < limite_inferior) | (matriz[coluna] > limite_superior)].index
    outlier_indices.update(indices)

    # Salva a quantidade de outliers da coluna
    contagem_por_coluna[coluna] = len(indices)

# Converte o set para lista antes de indexar
outliers_iqr = matriz.loc[list(outlier_indices)]

# Impress√£o dos resultados
print("Quantidade de outliers por coluna (IQR):")
for coluna, qtd in contagem_por_coluna.items():
    print(f"{coluna}: {qtd}")

print(f"\nTotal de linhas com pelo menos um outlier: {len(outliers_iqr)}")

print("\nOutliers detectados com IQR (linhas):")
print(outliers_iqr)

"""## 6.3.  Isolation Forest

Isolation Forest

* Detec√ß√£o de Outliers: O objetivo principal do c√≥digo √© identificar inst√¢ncias que s√£o consideradas outliers, ou seja, pontos que est√£o significativamente distantes dos dados "normais". A detec√ß√£o de outliers √© importante porque esses valores podem distorcer an√°lises estat√≠sticas ou influenciar negativamente o desempenho de modelos de aprendizado de m√°quina.

* Isolation Forest: √â uma t√©cnica eficiente para detectar outliers, especialmente quando os dados s√£o grandes ou de alta dimens√£o. Em compara√ß√£o com m√©todos tradicionais como o Z-Score ou IQR, o Isolation Forest √© mais eficaz em identificar outliers em dados que n√£o seguem uma distribui√ß√£o normal ou que s√£o complexos.

* An√°lise Complementar: A compara√ß√£o entre os valores dos outliers e os valores normais usando o IQR serve para verificar se os outliers identificados est√£o realmente fora do intervalo esperado e se esse comportamento √© consistente com a defini√ß√£o cl√°ssica de outlier.
"""

from sklearn.ensemble import IsolationForest
import pandas as pd
import numpy as np

# Seleciona apenas colunas num√©ricas
variaveis_numericas = matriz.select_dtypes(include='number')

# Inicializa e treina o modelo
# 0.02 -> 5% de outliers
iso_forest = IsolationForest(contamination=0.02, random_state=42)
outlier_flags = iso_forest.fit_predict(variaveis_numericas)

# Adiciona a predi√ß√£o ao DataFrame (-1 = outlier)
matriz['Outlier_IF'] = outlier_flags

# Total de inst√¢ncias com outliers
total_outliers = (outlier_flags == -1).sum()
print(f"Total de inst√¢ncias com outliers (Isolation Forest): {total_outliers} de {len(matriz)}")

# An√°lise por coluna
print("\nN√∫mero de outliers detectados por vari√°vel (Isolation Forest):")
col_outliers = {}
for col in variaveis_numericas.columns:
    # Compara distribui√ß√£o dos valores da vari√°vel entre outliers e n√£o-outliers
    outlier_vals = matriz.loc[matriz['Outlier_IF'] == -1, col]
    normal_vals = matriz.loc[matriz['Outlier_IF'] == 1, col]

    # Conta quantos outliers est√£o fora do intervalo interquartil da parte "normal"
    q1 = normal_vals.quantile(0.25)
    q3 = normal_vals.quantile(0.75)
    iqr = q3 - q1
    lower = q1 - 1.5 * iqr
    upper = q3 + 1.5 * iqr

    count = ((outlier_vals < lower) | (outlier_vals > upper)).sum()
    col_outliers[col] = count
    print(f"{col}: {count} inst√¢ncias")

# (Opcional) Ver gr√°fico ou salvar como DataFrame
# pd.Series(col_outliers).sort_values(ascending=False).plot(kind='barh')

"""## 6.4. Remo√ß√£o dos outliers

O c√≥digo que serve para filtrar e remover as inst√¢ncias identificadas como outliers do DataFrame, ap√≥s a aplica√ß√£o do modelo Isolation Forest.
"""

# Filtra apenas as linhas normais (n√£o outliers)
matriz_sem_outliers = matriz[matriz['Outlier_IF'] == 1].drop(columns='Outlier_IF').reset_index(drop=True)

print(f"N√∫mero de inst√¢ncias ap√≥s remo√ß√£o de outliers: {len(matriz_sem_outliers)}")

"""# 7. Salvar a matriz

Salva a matriz ap√≥s todo o tratamento como matriz_EDA
"""

from google.colab import files

# Salvar o DataFrame como CSV
matriz_sem_outliers.to_csv('matriz_EDA.csv', index=False)

# Fazer o download do arquivo CSV
files.download('matriz_EDA.csv')