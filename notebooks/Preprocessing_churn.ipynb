{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessamento"
      ],
      "metadata": {
        "id": "x4cXF1iVROE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Preprocessamento dos dados ocorre após a etapa de Análise Exploratória, na qual algumas transformações foram aplicadas à matriz de dados. Assim, a matriz carregada neste momento não corresponde aos dados brutos, mas sim à versão modificada após o EDA."
      ],
      "metadata": {
        "id": "7O8ODdJVQqO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação dos dados"
      ],
      "metadata": {
        "id": "VJ0ZU6LtaYdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Abre a janela para selecionar o arquivo\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Depois, para ler o arquivo\n",
        "import pandas as pd\n",
        "\n",
        "matriz = pd.read_csv('matriz_EDA.csv')"
      ],
      "metadata": {
        "id": "YVEZdVZ6Zwsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Multicolinearidade - análise antes do escalonamento"
      ],
      "metadata": {
        "id": "-M0-5NsNXZMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Correlação de Pearson/Spearman - valores"
      ],
      "metadata": {
        "id": "kRGyZPvJRciK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlação de Pearson/Spearman - valores: a correlação de Pearson é usada para medir a relação linear entre duas variáveis numéricas, enquanto a Spearman mede a relação monotônica. Ambas fornecem valores numéricos que indicam a força e a direção da relação entre variáveis, como entre MonthlyCharges e TotalCharges."
      ],
      "metadata": {
        "id": "-OGS-NhzYYgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlação de Pearson/Spearman - valores\n",
        "# Pearson: avalia relação linear (boa para variáveis contínuas normalmente distribuídas).\n",
        "# Spearman: avalia relação monótona (serve também para não lineares ou ordinais).\n",
        "# Correlação alta entre variáveis independentes pode causar multicolinearidade em modelos preditivos (e aí entra o VIF).\n",
        "\n",
        "# Correlação\tValor\tInterpretação\n",
        "# Positiva forte\t+0.7 a +1.0\tAmbas crescem juntas\n",
        "# Positiva moderada\t+0.4 a +0.69\tTendência de crescer juntas\n",
        "# Fraca / quase nula\t-0.3 a +0.3\tPouca ou nenhuma relação linear\n",
        "# Negativa moderada\t-0.4 a -0.69\tUma sobe enquanto a outra desce\n",
        "# Negativa forte\t-0.7 a -1.0\tRelação inversa forte\n",
        "\n",
        "\n",
        "# Seleciona apenas as colunas numéricas\n",
        "numericas = matriz.select_dtypes(include='number')\n",
        "\n",
        "# Correlação de Pearson\n",
        "print(\"\\nCorrelação de Pearson:\")\n",
        "print(numericas.corr(method='pearson'))\n",
        "\n",
        "# Correlação de Spearman\n",
        "print(\"\\nCorrelação de Spearman:\")\n",
        "print(numericas.corr(method='spearman'))"
      ],
      "metadata": {
        "id": "hIPqEnDDQVL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Correlação de Pearson/Spearman - heatmap"
      ],
      "metadata": {
        "id": "HcJTBp0CRn5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlação de Pearson/Spearman - heatmap: exibe visualmente as correlações entre múltiplas variáveis, usando uma matriz de correlação com cores para indicar a intensidade da relação. Essa análise é útil para identificar rapidamente quais variáveis têm correlação forte ou fraca entre si, facilitando a compreensão das interações entre os dados."
      ],
      "metadata": {
        "id": "PlhGllMXYhsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlação de Pearson/Spearman -heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seleciona colunas numéricas\n",
        "numericas = matriz.select_dtypes(include='number')\n",
        "\n",
        "# Heatmap da correlação de Pearson\n",
        "plt.figure(figsize=(20, 14))\n",
        "sns.heatmap(numericas.corr(method='pearson'), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Mapa de Correlação - Pearson\")\n",
        "plt.show()\n",
        "\n",
        "# Heatmap da correlação de Spearman\n",
        "plt.figure(figsize=(20, 14))\n",
        "sns.heatmap(numericas.corr(method='spearman'), annot=True, cmap='YlGnBu', fmt=\".2f\")\n",
        "plt.title(\"Mapa de Correlação - Spearman\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W8TEnmI7RWVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Análise de variáveis altamente correlacionadas"
      ],
      "metadata": {
        "id": "QuhQ7UDaOZCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código realiza uma análise de variáveis altamente correlacionadas no conjunto de dados. A ideia é identificar duplas de variáveis que possuem uma forte correlação, o que pode ser problemático em modelos de aprendizado de máquina ou regressão, pois pode levar a multicolinearidade e dificultar a interpretação dos resultados."
      ],
      "metadata": {
        "id": "6EMZdXVxHtOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Análise de variáveis altamente correlacionadas\n",
        "import numpy as np\n",
        "\n",
        "# Threshold de correlação alta\n",
        "threshold = 0.85\n",
        "\n",
        "# Seleciona apenas colunas numéricas\n",
        "numericas = matriz.select_dtypes(include='number')\n",
        "\n",
        "# Matriz de correlação absoluta\n",
        "cor_matrix = numericas.corr().abs()\n",
        "\n",
        "# Pega a parte superior da matriz para evitar duplicações\n",
        "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Identifica colunas com correlação acima do limiar\n",
        "altamente_correlacionadas = [col for col in upper_tri.columns if any(upper_tri[col] > threshold)]\n",
        "\n",
        "print(f\"\\nVariáveis altamente correlacionadas (r > {threshold}):\")\n",
        "print(altamente_correlacionadas)\n"
      ],
      "metadata": {
        "id": "eUPqHg7hSu2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Detecção de relações não-lineares"
      ],
      "metadata": {
        "id": "0umKAfJCOawS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O pairplot ajuda a visualizar relações não-lineares entre as variáveis numéricas, o que é importante porque a correlação de Pearson (usada nas análises lineares) não captura relações não-lineares. Ou seja, ele permite perceber padrões não-lineares ou interações complexas entre as variáveis que podem ser importantes para a modelagem.\n",
        "\n",
        "* Identificação de padrões não-lineares: Variáveis que não possuem uma correlação linear forte, mas que podem estar relacionadas de outras formas, como curvas ou outras formas não-lineares.\n",
        "\n",
        "* Insights sobre os dados: Pode ajudar a identificar transformações de variáveis ou interações entre elas que podem ser úteis em modelos de aprendizado de máquina, como a criação de novas características ou o uso de técnicas específicas para capturar relações não-lineares (por exemplo, árvores de decisão)."
      ],
      "metadata": {
        "id": "CqCDalWrIFFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecção de Relações Não-Lineares (via Pairplot + Spearman)\n",
        "# Pairplot ajuda a visualizar relações não-lineares\n",
        "sns.pairplot(matriz.select_dtypes(include='number'), kind='scatter', corner=True)\n",
        "plt.suptitle(\"Pairplot para relações não-lineares\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIZexLSFTLE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Boxplots por classe do target"
      ],
      "metadata": {
        "id": "Fk0vG5DeO-O5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código realiza a análise de variáveis numéricas em relação à variável alvo, 'Churn' (que provavelmente representa se o cliente abandonou ou não o serviço), utilizando boxplots para verificar a distribuição de cada variável numérica para cada classe do target (Churn)."
      ],
      "metadata": {
        "id": "-Or5PIejIglo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Verifica se a variável 'Churn' está no DataFrame\n",
        "if 'Churn' in matriz.columns:\n",
        "    # Selecionar variáveis numéricas (excluindo o target se for numérico)\n",
        "    variaveis_numericas = matriz.select_dtypes(include='number').columns.drop('Churn', errors='ignore')\n",
        "\n",
        "    for var in variaveis_numericas:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.boxplot(x='Churn', y=var, data=matriz)\n",
        "        plt.title(f\"Boxplot de {var} por classe do target (Churn)\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"A variável 'Churn' não foi encontrada no DataFrame.\")"
      ],
      "metadata": {
        "id": "TADrxhiRaLrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6. Correlação com o target"
      ],
      "metadata": {
        "id": "ein-nOR9PEvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código calcula a correlação de Pearson entre a variável target ('Churn') e as variáveis numéricas do DataFrame, para identificar o grau de relacionamento linear entre cada variável numérica e o target.\n",
        "\n",
        "A correlação de Pearson mede o grau de relacionamento linear entre duas variáveis. Ela varia entre -1 e 1, onde:\n",
        "\n",
        "* 1 indica uma correlação positiva perfeita (à medida que uma variável aumenta, a outra também aumenta).\n",
        "* -1 indica uma correlação negativa perfeita (à medida que uma variável aumenta, a outra diminui).\n",
        "* 0 indica nenhuma correlação linear."
      ],
      "metadata": {
        "id": "aIlXYz-SIoXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlação com o target (somente variáveis numéricas)\n",
        "# Correlação de Pearson entre variáveis numéricas e o target\n",
        "correlacoes = matriz.corr(numeric_only=True)['Churn'].drop('Churn').sort_values(ascending=False)\n",
        "print(\"Correlação com o target:\")\n",
        "print(correlacoes)\n",
        "\n"
      ],
      "metadata": {
        "id": "ofvbruVcdZNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Separação do dataset - treinamento e teste"
      ],
      "metadata": {
        "id": "wOmyNWZ8ZbcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação dos dados em treinamento e teste\n",
        "#matriz (completa)\n",
        "#dados_train (treino)\n",
        "#dados_test (teste)\n",
        "# 80% treinamento e 20% teste\n",
        "# random_state para garantir a reprodutibilidade\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separação\n",
        "dados_train, dados_test = train_test_split(matriz,\n",
        "                                           test_size=0.2,\n",
        "                                           random_state=35)\n",
        "\n",
        "# Conferência\n",
        "print(\"Matriz completa: {} instâncias\\n{} instâncias de treino\\n{} instâncias de teste\".\n",
        "      format(len(matriz), len(dados_train), len(dados_test)))\n"
      ],
      "metadata": {
        "id": "8B4ESlIA_xDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Escalonamento - zscore"
      ],
      "metadata": {
        "id": "kR7VM1FqT3XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Escalonamento - z-score\n",
        "#Escalonar no treino e guardar a média e o desvio padrão para aplicar nos dados de teste.\n",
        "# O StandardScaler aplica o Z-Score em cada variável, mas como é preciso guardar média e desvio, foi feito de maneira manual.\n",
        "# Z-score: subtrai a média (centraliza os dados em 0) e divide pelo desvio padrão (ajusta a escala para variância 1)\n",
        "# o StandardScaler, na prática, está fazendo o Z-Score em todas as colunas numéricas escolhidas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Seleciona apenas colunas numéricas (excluindo a coluna 'Churn')\n",
        "colunas_numericas = dados_train.drop('Churn', axis=1).select_dtypes(include=np.number).columns\n",
        "\n",
        "# Calcula a média e o desvio padrão apenas com os dados de treino\n",
        "medias = dados_train[colunas_numericas].mean()\n",
        "desvios = dados_train[colunas_numericas].std()\n",
        "\n",
        "# Salva essas informações\n",
        "media_desvio_dict = {\n",
        "    'medias': medias,\n",
        "    'desvios': desvios\n",
        "}\n",
        "\n",
        "# Faz o escalonamento do treino\n",
        "x_dados_train_escalado = dados_train.copy()\n",
        "x_dados_train_escalado[colunas_numericas] = (dados_train[colunas_numericas] - medias) / desvios\n",
        "\n",
        "# Faz o escalonamento do teste usando as médias e desvios do treino\n",
        "x_dados_test_escalado = dados_test.copy()\n",
        "x_dados_test_escalado[colunas_numericas] = (dados_test[colunas_numericas] - medias) / desvios\n",
        "\n",
        "# Cria as variáveis de target (y) para treino e teste\n",
        "y_dados_train_escalado = dados_train['Churn']\n",
        "y_dados_test_escalado = dados_test['Churn']"
      ],
      "metadata": {
        "id": "7JmgGArtMvZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= x_dados_train_escalado.drop('Churn', axis=1)\n",
        "x_test= x_dados_test_escalado.drop('Churn', axis=1)\n",
        "y_train=y_dados_train_escalado\n",
        "y_test=y_dados_test_escalado"
      ],
      "metadata": {
        "id": "6bMovsQUNY51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Multicolinearidade - Análise após o escalonamento"
      ],
      "metadata": {
        "id": "trfZi3RZg37t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matriz=x_train"
      ],
      "metadata": {
        "id": "j5cLUIJGiwqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. VIF (Variance Inflation Factor) para multicolinearidade"
      ],
      "metadata": {
        "id": "IodS7PnAhXwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O VIF (Variance Inflation Factor) é uma métrica utilizada para verificar a multicolinearidade em um conjunto de dados, ou seja, a correlação entre variáveis independentes. Quando variáveis independentes estão altamente correlacionadas entre si, a multicolinearidade pode distorcer as estimativas de um modelo de regressão, tornando-o menos confiável.\n",
        "\n",
        "* O VIF mede o quanto a variabilidade de uma variável independente está inflacionada devido à correlação com outras variáveis independentes.\n",
        "\n",
        "* Um VIF alto (geralmente maior que 5 ou 10, dependendo da referência) indica multicolinearidade alta, o que pode afetar a precisão dos coeficientes do model"
      ],
      "metadata": {
        "id": "yGwsiasjhXwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIF (Variance Inflation Factor) para multicolinearidade\n",
        "# Valores de VIF > 5 (ou 10, a depender da referência) indicam multicolinearidade alta.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "import pandas as pd\n",
        "\n",
        "# Seleciona variáveis numéricas\n",
        "X = matriz.select_dtypes(include='number').dropna()  # Remove linhas com NaN\n",
        "\n",
        "# Adiciona constante para o cálculo do VIF\n",
        "X_const = add_constant(X)\n",
        "\n",
        "# Calcula VIF\n",
        "vif = pd.DataFrame()\n",
        "vif['Variável'] = X.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_const.values, i + 1) for i in range(len(X.columns))]\n",
        "\n",
        "print(\"\\nVIF (Variance Inflation Factor):\")\n",
        "print(vif.sort_values(by='VIF', ascending=False))\n"
      ],
      "metadata": {
        "id": "-AJKER5ehXwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Matriz de correlação"
      ],
      "metadata": {
        "id": "UMR7HTLphXwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# matriz de correlação\n",
        "#Quando duas variáveis têm correlação muito alta (ex: > 0,9 ou < -0,9), pode ser problema.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular a matriz de correlação\n",
        "correlacao = matriz.corr(numeric_only=True)\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlacao, annot=True, cmap='coolwarm')\n",
        "plt.title('Matriz de Correlação')\n",
        "plt.show()\n",
        "\n",
        "# Como resolver a multicolinearidade:\n",
        "  #Remover uma das variáveis altamente correlacionadas.\n",
        "  #Combinar variáveis correlacionadas (ex: média, soma).\n",
        "  #Reduzir Dimensionalidade: usar técnicas como PCA (Principal Component Analysis).\n",
        "  #Modelos robustos: alguns algoritmos lidam bem com multicolinearidade (ex: árvore de decisão).\n"
      ],
      "metadata": {
        "id": "lARbxtszhXwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Determinante da matriz de correlação"
      ],
      "metadata": {
        "id": "YQ-jNLL6hXwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinante da matriz de correlação\n",
        "# Se o determinante for próximo de 0 → existe multicolinearidade.\n",
        "import numpy as np\n",
        "\n",
        "corr_matrix = matriz.corr(numeric_only=True)\n",
        "determinante = np.linalg.det(corr_matrix)\n",
        "\n",
        "print(f\"Determinante da matriz de correlação: {determinante:.6f}\")\n"
      ],
      "metadata": {
        "id": "pb_kr2k2hXwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. Eigenvalues (autovalores) da matriz de correlação"
      ],
      "metadata": {
        "id": "o1zN5-tkhXwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Eigenvalues (autovalores) da matriz de correlação\n",
        "#Quando um ou mais autovalores são muito pequenos (próximos de zero), indica que há combinações lineares entre variáveis.\n",
        "eigenvalues, _ = np.linalg.eig(corr_matrix)\n",
        "\n",
        "print(\"Autovalores:\")\n",
        "print(eigenvalues)\n"
      ],
      "metadata": {
        "id": "mlTte3A4hXwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Solução para multicolinearidade - PCA"
      ],
      "metadata": {
        "id": "1VxrrqoteA_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 1. Aplicação do PCA com 95% da variância explicada\n",
        "pca = PCA(n_components=0.95)\n",
        "x_train_pca = pca.fit_transform(x_train) # PCA ajustado com base no treino\n",
        "x_test_pca = pca.transform(x_test) # PCA aplica a transformação com base no ajuste anterior\n",
        "\n",
        "# 2. Exibição das informações solicitadas\n",
        "print(\"Número de colunas antes do PCA:\", x_train.shape[1])\n",
        "print(\"Número de componentes principais após o PCA:\", pca.n_components_)\n",
        "print(\"Variância explicada por componente:\")\n",
        "for i, var in enumerate(pca.explained_variance_ratio_):\n",
        "    print(f\"  PC{i+1}: {var:.4f}\")\n",
        "\n",
        "# 3. Conversão para DataFrame com nomes de colunas \"PC1\", \"PC2\", ...\n",
        "pc_columns = [f\"PC{i+1}\" for i in range(pca.n_components_)]\n",
        "x_train_pca_df = pd.DataFrame(x_train_pca, columns=pc_columns)\n",
        "x_test_pca_df = pd.DataFrame(x_test_pca, columns=pc_columns)\n",
        "\n",
        "# Exibe as primeiras linhas\n",
        "print(\"\\nPrimeiras linhas do x_train_pca:\")\n",
        "print(x_train_pca_df.head())"
      ],
      "metadata": {
        "id": "J5dKu759elIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train_pca_df\n",
        "x_test=x_test_pca_df"
      ],
      "metadata": {
        "id": "t1IkkSSlNsJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Salvar as matrizes de treinamento e teste"
      ],
      "metadata": {
        "id": "fJOSm7qnjnb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Treinamento\n",
        "# Salvar o DataFrame de treino como CSV\n",
        "x_train.to_csv('x_train.csv', index=False)\n",
        "# Fazer o download do arquivo CSV\n",
        "files.download('x_train.csv')\n",
        "\n",
        "# Salvar o target de treino como CSV\n",
        "y_train.to_csv('y_train.csv', index=False)\n",
        "# Fazer o download do arquivo CSV\n",
        "files.download('y_train.csv')\n",
        "\n",
        "\n",
        "# Teste\n",
        "# Salvar o DataFrame de teste como CSV\n",
        "x_test.to_csv('x_test.csv', index=False)\n",
        "# Fazer o download do arquivo CSV\n",
        "files.download('x_test.csv')\n",
        "# Salvar o target de teste como CSV\n",
        "y_test.to_csv('y_test.csv', index=False)\n",
        "# Fazer o download do arquivo CSV\n",
        "files.download('y_test.csv')"
      ],
      "metadata": {
        "id": "3IgaLqMEjotg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}